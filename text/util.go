package text

import (
	"bufio"
	"context"
	"io"
	"os"
	"runtime"
	"slices"
	"sync"
	"telescope/feature"
	"time"

	"golang.org/x/exp/mmap"
)

func padNewLine(line []byte) []byte {
	if line[len(line)-1] == '\n' {
		return line
	}
	return append(slices.Clone(line), '\n')
}

func endOfLineSize(line []byte) int {
	if len(line) == 0 {
		panic("empty line")
	}
	if line[len(line)-1] != '\n' {
		panic("not end of line")
	}
	if len(line) >= 2 && line[len(line)-2] == '\r' {
		// for windows
		return 2
	}
	return 1
}

func indexFile(ctx context.Context, filename string, update func(offset int, line []byte)) {
	f, err := os.Open(filename)
	if err != nil {
		panic(err)
	}
	defer f.Close()
	var offset int = 0
	reader := bufio.NewReader(f)
	for {
		select {
		case <-ctx.Done():
			return
		default:
		}
		line, err := reader.ReadBytes('\n')
		if err != nil && err != io.EOF {
			panic(err)
		}
		if len(line) > 0 {
			if feature.Debug() {
				time.Sleep(feature.DEBUG_IO_INTERVAL_MS * time.Millisecond)
			}
			update(offset, line)
		}
		if err == io.EOF {
			break
		}
		offset += len(line)
	}
}

// indexFileParallel - code generated by chatgpt - similar to indexFile but load file in parallel
func indexFileParallel(ctx context.Context, filename string, update func(offset int, line []byte)) {
	type lineMeta struct {
		offset int
		line   []byte
	}

	fi, err := os.Stat(filename)
	if err != nil {
		panic(err)
	}
	fileSize := fi.Size()

	r, err := mmap.Open(filename)
	if err != nil {
		panic(err)
	}

	numWorkers := runtime.NumCPU()
	chunkSize := fileSize / int64(numWorkers)

	workerOut := make([]chan lineMeta, numWorkers)
	var wg sync.WaitGroup

	for i := 0; i < numWorkers; i++ {
		start := int64(i) * chunkSize
		end := start + chunkSize
		if i == numWorkers-1 {
			end = fileSize
		}

		// ✅ Adjust start to next newline (skip partial line)
		if i != 0 {
			buf := make([]byte, 1)
			for {
				if start >= fileSize {
					break // safety
				}
				_, err := r.ReadAt(buf, start)
				if err != nil {
					panic(err)
				}
				if buf[0] == '\n' {
					start++
					break
				}
				start++
			}
		}

		// ✅ Adjust end to include full line
		if end < fileSize {
			buf := make([]byte, 1)
			for {
				_, err := r.ReadAt(buf, end)
				if err != nil {
					break
				}
				if buf[0] == '\n' {
					end++
					break
				}
				end++
			}
			if end > fileSize {
				end = fileSize
			}
		}

		ch := make(chan lineMeta, 1024) // buffered channel
		workerOut[i] = ch
		wg.Add(1)

		go func(start, end int64, ch chan<- lineMeta) {
			defer close(ch)
			defer wg.Done()

			buf := make([]byte, end-start)
			_, err := r.ReadAt(buf, start)
			if err != nil && err != io.EOF {
				panic(err)
			}

			relOffset := 0
			for i, b := range buf {
				if b == '\n' {
					if feature.Debug() {
						time.Sleep(feature.DEBUG_IO_INTERVAL_MS * time.Millisecond)
					}
					select {
					case <-ctx.Done():
						return
					default:
					}
					ch <- lineMeta{
						offset: int(start) + relOffset,
						line:   buf[relOffset : i+1],
					}
					relOffset = i + 1
				}
			}
			// ✅ handle trailing line with no '\n'
			if relOffset < len(buf) {
				line := buf[relOffset:]
				ch <- lineMeta{
					offset: int(start) + relOffset,
					line:   line,
				}
			}
		}(start, end, ch)
	}

	// ✅ Eager and ordered emission
	for _, ch := range workerOut {
		for meta := range ch {
			update(meta.offset, meta.line)
		}
	}

	wg.Wait()

	return

}
